---
layout: default
title: My Machine Learning track
lang: en
ref: ml-track
---
<h2>My Machine Learning Track</h2>

<h3> The tools i've been using</h3> 
<ul> 
	<li>Python</li>
	<li>Numpy</li>
	<li>Pandas</li>
	<li>Scikit-learn</li>
	<li>Keras</li>
	<li>Scipy stats</li>
	<li>Matplotlib and Seaborn</li>
</ul>

<h3>Personal Project / Research: </h3>
<ul>
	<li>
		<p> 
		I've been building an e-mail classifier for Code Club Brasil with a multilabel approach, the idea is to build an automated email responder. A professor from IME-USP helps me with advices when we meet to discuss the problem, it may become my graduation thesis. It's been nice to face a ML in such holistic way, since i've collected and labeled the data and i need to both discover the questions and answer them. I'm dealing with a lot of issues, as a small dataset and skewed labels. There's a long list of things to try, but the best until now is a 51% Global Acc.   
		The Notebook with my first experiments can be seen <a href="projects/ccbr emails - apr.html">here.</a></p>
		<p> 
		<a href="projects/example1.png">A bad prediction example.</a>
		</p>	
		<p> 
		<a href="projects/example2.png">A good prediction example.</a>
		</p>	
	</li>
</ul>

<h3> Hackatons / Competitions </h3>
<p>
	My <a href="https://www.kaggle.com/lgmoneda">Kaggle Profile</a>. 
</p>
<ul>
	<li>
		<p>
		 	<a href="http://www.datasciencegame.com/ ">DataScienceGame 2016</a>'s selection: An image classification competition between teams from universities runned in <a href="https://inclass.kaggle.com/c/data-science-game-2016-online-selection">Kaggle</a>. Result: 38<span style="vertical-align: super; font-size: 0.5em;">th</span> in 117 teams. Though we haven't classified to the second phase, it was a great learning oportunity. My <a href="course1/week1/index.html">notebook</a> can be seen here.   
		</p>
	</li>
	<li>
		<p>
		 	Kaggle's <a href="https://www.kaggle.com/c/sf-crime">San Francisco Crime Classification</a>: A classic multi-class problem. My first competition in Kaggle. Result: 198<span style="vertical-align: super; font-size: 0.5em;">th</span> in 2335 teams. Finished almost 2 months ago, but no private leaderboard yet. Here one notebook i used <a href="hackatons/2/the crimes.html">notebook</a>, though some grid search and xgboost were done in different files.   
		</p>
	</li>
	<li>
		<p>
		 	My very first hackaton, i wasn't using Pandas neither Jupyter Notebook. Though it's nice to implement from scratch, i'm happy i'm now using Pandas and not writing OHE functions to Numpy Arrays. Result: 6-10<span style="vertical-align: super; font-size: 0.5em;">th</span> in 120 competitors. Here's the <a href="https://github.com/lgmoneda/hackatons/blob/master/avidhya/loan-prediction/loan-hackaton.py">code</a>.   
		</p>
	</li>
</ul>

<h3>Introduction to Computer Intelligence Assignments (Poli 2016/1)</h3>
<p> 
	Some basic ML Models built from scratch, i tried to follow scikit-learn methods names.
</p>
<img style="float:right;width:300px;" src="PTC2669/xor2.png" alt="24/07/2016">
<ul>
	<li>
		<p>
			Linear Regression using Least Mean Squares, plots from weights evolution, learning curves and fitted model: <a href="PTC2669/PTC2669 - Lista 1 LMS Final.html">notebook.</a>
		</p>
	</li>
	<li>
		<p>
			The Perceptron, plots with classes and the learned boundary line: <a href="PTC2669/Lista 3 - PTC2669.html">notebook.</a>
		</p>
	</li>
	<li>
		<p>
			Multi Layer Perceptron solving the XOR problem: <a href="PTC2669/Lista 4 - PTC2669.html">notebook.</a>
		</p>
	</li>
</ul>

<h3>Machine Learning Specialization - Washington University (Coursera)</h3>
<p> Nice series of courses. We use numpy in the low level assignments (implementing algorithms) and graphlab, a ml library from Turi (former Dato), in the high level ones. They give us a skeleton, so the code isn't entirely written by me. I'm doing the course 4 now.	
</p>
<ol>
	<li>
		<h4>A case study approach </h4>
		<ol>
			<li><a href="UW/1/Predicting+house+prices">Predicting House Prices.</a></li>
			<li><a href="UW/1/Analyzing+product+sentiment">Analyzing product sentiment.</a></li>
			<li><a href="UW/1/Analyzing+product+sentiment2">Analyzing product sentiment II.</a></li>
			<li><a href="UW/1/Document+retrieval.html">Document retrieval.</a></li>
			<li><a href="UW/1/Song+recommender">Song recommender.</a></li>
			<li><a href="UW/1/Deep+Features+for+Image+Classification">Deep Features for Image Classification.</a></li>
			<li><a href="UW/1/Deep+Features+for+Image+Retrieval.html">Deep Features for Image Retrieval.</a></li>
		</ol>
	</li>
	<li>
	<h4>Regression</h4>
	<ol>
		<li><a href="UW/2/week-1-simple-regression-done">Simple Regression.</a></li>
		<li><a href="UW/2/week-2-multiple-regression-assignment-1-blank">Multiple Regression.</a></li>
		<li><a href="UW/2/week-2-multiple-regression-assignment-2-blank">Multiple Regression II (Gradient descent).</a></li>
		<li><a href="UW/2/week-3-polynomial-regression-assignment-blank">Polynomial Regression.</a></li>
		<li><a href="UW/2/week-4-ridge-regression-assignment-1-blank">Ridge Regression.</a></li>
		<li><a href="UW/2/week-4-ridge-regression-assignment-2-blank">Ridge Regression II.</a></li>
		<li><a href="UW/2/week-5-lasso-assignment-1-blank.html">Lasso Regression.</a></li>
		<li><a href="UW/2/week-5-lasso-assignment-2-blank.html">Lasso Regression II.</a></li>
		<li><a href="UW/2/week-6-local-regression-assignment-blank.html">Local Regression.</a></li>
	</ol>
	</li>
		<li>
	<h4>Classification</h4>
		<ol>
		<li><a href="UW/3/module-2-linear-classifier-assignment-blank">Linear classifier.</a></li>
		<li><a href="UW/3/module-3-linear-classifier-learning-assignment-blank">Logistic Regression.</a></li>
		<li><a href="UW/3/module-4-linear-classifier-regularization-assignment-blank">Logistic Regression with L2 regularization.</a></li>
		<li><a href="UW/3/module-5-decision-tree-assignment-1-blank">Decision Tree.</a></li>
		<li><a href="UW/3/module-5-decision-tree-assignment-2-blank">Binary Decision Tree.</a></li>
		<li><a href="UW/3/module-6-decision-tree-practical-assignment-blank">Decision Tree in Pratice.</a></li>
		<li><a href="UW/3/module-8-boosting-assignment-1-blank.html">Exploring Ensemble methods..</a></li>
		<li><a href="UW/3/module-8-boosting-assignment-2-blank">Boosting a Decision stump.</a></li>
		<li><a href="UW/3/module-9-precision-recall-assignment-blank.html">Exploring Precision and Recall.</a></li>
		<li><a href="UW/3/module-10-online-learning-assignment-blank.html">Stochastic Gradient Descent.</a></li>
	</ol>
	</li>
</ol>

<h3>Data Analysis and Interpretation Specialization (Coursera, 2016/1)</h3>
<p> 
	Only the two first courses from the specialization. It was a good oportunity to review hypothesis tests and uso scipy.stats. The assignments are <a href="http://lgmoneda.github.io/data_science_coursera/">here</a>.
</p>

<h3>Others</h3>
<p> 
	There're other courses that are related with Machine Learning, Data Science and Python, they're listed in my <a href="http://lgmoneda.github.io/cv/">cv</a>.
</p>