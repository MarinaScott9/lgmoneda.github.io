---
layout: default
title: My Machine Learning track
lang: en
ref: ml-track
---
<h2>My Machine Learning Track</h2>

<h3> The tools i've been using</h3> 
<ul> 
	<li>Python</li>
	<li>Numpy</li>
	<li>Pandas</li>
	<li>Scikit-learn</li>
	<li>Keras</li>
	<li>Scipy stats</li>
	<li>Matplotlib and Seaborn</li>
</ul>

<h3> Hackatons / Competitions </h3>
<p>
	My <a href="https://www.kaggle.com/lgmoneda">Kaggle Profile</a>. 
</p>
<ul>
	<li>
		<p>
		 	<a href="http://www.datasciencegame.com/ ">DataScienceGame 2016</a>'s selection: An image classification competition between teams from universities runned in <a href="https://inclass.kaggle.com/c/data-science-game-2016-online-selection">Kaggle</a>. Result: 38<span style="vertical-align: super; font-size: 0.5em;">th</span> in 117 teams. Though we haven't classified to the second phase, it was a great learning oportunity. My <a href="course1/week1/index.html">notebook</a> can be seen here.   
		</p>
	</li>
	<li>
		<p>
		 	Kaggle's <a href="https://www.kaggle.com/c/sf-crime">San Francisco Crime Classification</a>: A classic multi-class problem. My first competition in Kaggle. Result: 198<span style="vertical-align: super; font-size: 0.5em;">th</span> in 2335 teams. Finished almost 2 months ago, but no private leaderboard yet. Here's my <a href="course1/week1/index.html">notebook</a>.   
		</p>
	</li>
	<li>
		<p>
		 	My very first hackaton, i wasn't using Pandas neither Jupyter Notebook. Though it's nice to implement from scratch, i'm happy i'm now using Pandas and not writing OHE functions to Numpy Arrays. Result: 6-10<span style="vertical-align: super; font-size: 0.5em;">th</span> in 120 competitors. Finished almost 2 months ago, but no private leaderboard yet. Here's the <a href="course1/week1/index.html">code</a>.   
		</p>
	</li>
</ul>

<h3>Personal Project / Research: </h3>
<ul>
	<li>
		<p> 
		I've been building an e-mail classifier for Code Club Brasil with a multilabel approach, the idea is to build an automated email responder. A professor from USP helps me with advices when we meet to discuss the problem, it may become my graduation thesis. It's been nice to face the hole process, since i collected and labeled the data.   
		</p>
	<a href="course1/week1/index.html">Question </a>
	</li>
</ul>

<h3>Introduction to Computer Intelligence Assignments (Poli 2016/1)</h3>
<p> 
	Some basic ML Models built from scratch, i tried to follow scikit-learn methods names.
</p>
<img style="float:right;width:300px;" src="PTC2669/xor2.png" alt="24/07/2016">
<ul>
	<li>
		<p>
			Linear Regression using Least Mean Squares, plots from weights evolution, learning curves and fitted model: <a href="PTC2669/PTC2669 - Lista 1 LMS Final.html">notebook.</a>
		</p>
	</li>
	<li>
		<p>
			The Perceptron, plots with classes and the learned boundary line: <a href="PTC2669/Lista 3 - PTC2669.html">notebook.</a>
		</p>
	</li>
	<li>
		<p>
			Multi Layer Perceptron solving the XOR problem: <a href="PTC2669/Lista 4 - PTC2669.html">notebook.</a>
		</p>
	</li>
</ul>

<h3>Machine Learning Specialization - Washington University (Coursera)</h3>
<p> Nice series of courses. We use numpy in the low level assignments (implementing algorithms) and graphlab, a ml library from Turi (former Dato), in the high level ones. They give us a skeleton, so the code isn't entirely written by me. I'm doing the course 4 now.	
</p>
<ol>
	<li>
		<h4>A case study approach </h4>
		<ol>
			<li><a href="UW/1/Predicting+house+prices">Predicting House Prices.</a></li>
			<li><a href="UW/1/Analyzing+product+sentiment">Analyzing product sentiment.</a></li>
			<li><a href="UW/1/Analyzing+product+sentiment2">Analyzing product sentiment II.</a></li>
			<li><a href="UW/1/Document+retrieval.html">Document retrieval.</a></li>
			<li><a href="UW/1/Song+recommender">Song recommender.</a></li>
			<li><a href="UW/1/Deep+Features+for+Image+Classification">Deep Features for Image Classification.</a></li>
			<li><a href="UW/1/Deep+Features+for+Image+Retrieval.html">Deep Features for Image Retrieval.</a></li>
		</ol>
	</li>
	<li>
	<h4>Regression</h4>
	<ol>
		<li><a href="UW/2/week-1-simple-regression-done">Simple Regression.</a></li>
		<li><a href="UW/2/week-2-multiple-regression-assignment-1-blank">Multiple Regression.</a></li>
		<li><a href="UW/2/week-2-multiple-regression-assignment-2-blank">Multiple Regression II (Gradient descent).</a></li>
		<li><a href="UW/2/week-3-polynomial-regression-assignment-blank">Polynomial Regression.</a></li>
		<li><a href="UW/2/week-4-ridge-regression-assignment-1-blank">Ridge Regression.</a></li>
		<li><a href="UW/2/week-4-ridge-regression-assignment-2-blank">Ridge Regression II.</a></li>
		<li><a href="UW/2/Deep+Features+for+Image+Retrieval">Deep Features for Image Retrieval.</a></li>
	</ol>
	</li>
		<li>
	<h4>A case study approach </h4>
	</li>
</ol>


<h3>Data Analysis and Interpretation Specialization (Coursera, 2016/1)</h3>
<p> 
	Only the two first courses from the specialization. It was a good oportunity to review hypothesis tests and uso scipy.stats. The assignments are <a href="http://lgmoneda.github.io/data_science_coursera/">here</a>.
</p>